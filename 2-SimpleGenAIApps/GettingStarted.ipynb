{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"Lanchain_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x00000193A903DD80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000193A90985B0> root_client=<openai.OpenAI object at 0x00000193A903C370> root_async_client=<openai.AsyncOpenAI object at 0x00000193A903D060> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence models designed to generate new content or data that resembles existing data. These models can create text, images, music, and other forms of media. The primary goal of generative AI is to produce outputs that are indistinguishable from those created by humans or that possess certain desired characteristics.\\n\\nOne of the most popular techniques used in generative AI is the Generative Adversarial Network (GAN), which consists of two neural networks—a generator and a discriminator—that work together in a competitive setting. Another widely used approach is the Variational Autoencoder (VAE), which focuses on learning efficient representations of data for generation purposes.\\n\\nIn recent years, models like OpenAI's GPT (Generative Pre-trained Transformer) series and Google's BERT (Bidirectional Encoder Representations from Transformers) have demonstrated impressive capabilities in generating human-like text. These models are based on deep learning architectures that leverage large datasets to capture the nuances of language.\\n\\nGenerative AI has a wide range of applications, including but not limited to:\\n\\n1. **Content Creation**: Automating the generation of articles, poetry, or reports.\\n2. **Image and Video Synthesis**: Creating realistic images or videos from scratch, useful in fields like entertainment, advertising, and design.\\n3. **Music Composition**: Generating original music compositions in various styles.\\n4. **Drug Discovery**: Designing new molecules or compounds for pharmaceutical research.\\n5. **Data Augmentation**: Generating new synthetic data to improve machine learning model training.\\n\\nDespite its potential, generative AI also raises ethical and societal concerns, such as the creation of deepfakes, the spread of misinformation, and intellectual property issues. As a result, there is ongoing research and debate on how to manage the risks associated with these technologies.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 364, 'prompt_tokens': 12, 'total_tokens': 376, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_2f406b9113', 'finish_reason': 'stop', 'logprobs': None} id='run-7c0e09c8-d795-46d3-ac6c-28d912721247-0' usage_metadata={'input_tokens': 12, 'output_tokens': 364, 'total_tokens': 376, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Generative AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        \n",
    "            (\"system\",\"You are an expert AI Engineer. Provide me answers based on the question\"),\n",
    "            (\"user\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a tool developed by LangChain that provides a comprehensive platform for testing, evaluating, and monitoring applications built with language models. It is designed to help developers optimize the performance and reliability of their language model applications.\\n\\nKey features of Langsmith include:\\n\\n1. **Testing and Evaluation**: Langsmith offers tools for thorough testing and evaluation of language models, allowing developers to understand how different models perform on specific tasks or datasets. This helps in selecting the most appropriate model for a given application.\\n\\n2. **Monitoring**: It provides monitoring capabilities to track the performance of language models in real-time. This includes keeping an eye on metrics like latency, accuracy, and usage patterns, which are crucial for maintaining the quality and reliability of model-driven applications.\\n\\n3. **Feedback and Iteration**: Langsmith facilitates collecting user feedback and iterating on model performance, ensuring continuous improvement and adaptation to user needs.\\n\\n4. **Integration with LangChain**: As part of the LangChain ecosystem, Langsmith is designed to integrate seamlessly with other tools and libraries provided by LangChain, enhancing its utility in building robust language model applications.\\n\\nOverall, Langsmith is aimed at developers and teams looking to build, test, and maintain high-quality applications that rely on language models, providing them with the necessary tools to ensure their applications perform well in production environments.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 268, 'prompt_tokens': 33, 'total_tokens': 301, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9e15ccd6a4', 'finish_reason': 'stop', 'logprobs': None}, id='run-fca7a675-db70-4528-ba34-b0c5fedc53a9-0', usage_metadata={'input_tokens': 33, 'output_tokens': 268, 'total_tokens': 301, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain=prompt|llm|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform developed by LangChain designed to enhance the development and deployment of applications that utilize large language models (LLMs). It provides a suite of tools and services that assist developers in various stages of the application lifecycle, including prototyping, testing, evaluating, and monitoring applications that leverage LLMs and chains.\n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Integrated Development Environment (IDE):** Langsmith offers an IDE that simplifies the process of building and iterating on applications that use LLMs. This environment allows developers to prototype quickly and make real-time adjustments to their models and chains.\n",
      "\n",
      "2. **Evaluation and Testing:** Langsmith provides robust tools for testing and evaluating LLMs, enabling developers to understand how their models perform under different scenarios and with various inputs. This helps in refining models for better accuracy and performance.\n",
      "\n",
      "3. **Monitoring and Logging:** The platform includes monitoring capabilities to track the performance and usage of deployed applications. This includes logging features that help in diagnosing issues and understanding user interactions.\n",
      "\n",
      "4. **Collaboration and Sharing:** Langsmith facilitates collaboration among developers by allowing them to share their work, insights, and findings, fostering a community of innovation and collective problem-solving.\n",
      "\n",
      "Overall, Langsmith aims to streamline the workflow for developers working with language models, making it easier to build efficient, reliable, and scalable LLM-based applications.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
